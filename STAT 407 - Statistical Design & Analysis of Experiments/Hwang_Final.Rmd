---
title: "Hwang_Final"
author: "Charles Hwang"
date: "12/17/2021"
output: pdf_document
---
## Problem 1
(a)

Model: $y$ = $\beta_0$ + $\beta_1x_1$ + $\beta_2x_2$ + $\beta_{11}x_1^2$ + $\beta_{22}x_2^2$ + $\beta_{12}x_1x_2$ + $\epsilon$

$y$: response variable (body mass index)

$\beta_0$: intercept term

$\beta_1$: intercept term for $x_1$

$x_1$: coded variable for age

$\beta_2$: intercept term for $x_2$

$x_2$: coded variable for blood pressure

$\beta_{11}$: intercept term for $x_1^2$ (quadratic term for $x_1$)

$\beta_{22}$: intercept term for $x_2^2$ (quadratic term for $x_2$)

$\beta_{12}$: intercept term for interaction between $x_1$ and $x_2$

$\epsilon$: error term

```{r Problem 1(a), warning=FALSE}
rm(list=ls())
library(mlbench)
data(PimaIndiansDiabetes)
set.seed(211712,sample.kind="Rounding")
final<-PimaIndiansDiabetes[sample(nrow(PimaIndiansDiabetes),50),]
final[final["mass"]==0,]
# We can see observation 685 (number 14 in our subset) has mass recorded as "0". Given
# the dataset and variables, this appears to be missing data and we should exclude
# this observation whenever using our subset for the remainder of Problem 1.
y<-final[-14,"mass"] # Removing observation from variables
x1<-final[-14,"age"]
x2<-final[-14,"pressure"]
m<-lm(y~x1*x2+I(x1^2)+I(x2^2))
anova(m)
# We can see blood pressure (x2) and the quadratic term for age (x1^2) are both
# significant at the alpha = 0.05 level (p = 0.026747, p = 0.009191), but
# age (x1), the quadratic term for blood pressure (x2^2), and the interaction
summary(m) # term (x1*x2) are not (p = 0.123318, p = 0.051218, p = 0.508977). 
# We can see age (x1) and the quadratic term for age (x1^2) are significant at the
# alpha = 0.05 level (p = 0.03763, p = 0.00906), but the intercept term, blood
# pressure (x2), the quadratic term for blood pressure (x2^2), and the interaction
# term (x1*x2) are not (p = 0.10674, p = 0.45406, p = 0.05369, p = 0.50898).
qq<-qqnorm(abs(m$effects[-1]),type="n") # Remove variables
text(qq$x,qq$y,labels=names(abs(m$effects[-1])))
abline(h=9.8,lty=2) # Age (x1) was cut from the reduced model because it was not
# significant in either the analysis of variance (ANOVA) or the model. However, I
# believe the quadratic term for blood pressure (x2^2) is close enough to being
# significant (p = 0.051218, p = 0.05369) that it should still be included in the model.
legend(-2.39,15,"x = 9.8",lty=2)
n<-lm(y~x2+I(x1^2)+I(x2^2)) # New model
anova(n)
# We can see blood pressure (x2), the quadratic term for age (x1^2) and the quadratic
# term for blood pressure (x2x2) are all significant at the alpha = 0.05
# level (p = 0.03529, p = 0.04747, p = 0.03419). This is expected because these three
summary(n)     # variables were the only significant variables in the original model.
# We can see the intercept, quadratic term for age (x1^2), and the quadratic term for
# blood pressure (x2^2) are all significant at the alpha = 0.05 level (p < 0.00001,
# p = 0.00915, p = 0.03419), also as expected. However, blood pressure (x2) is
shapiro.test(n$residuals)        # not significant in the model (p = 0.13793).
# The null hypothesis was not rejected (p = 0.2894) at the alpha = 0.05 level,
par(mfrow=c(1,2))             # so the normality assumption appears to be met.
qqnorm(n$residuals)
qqline(n$residuals)
plot(n$fitted.values,n$residuals)
abline(h=0)
# There is a slight variation in the Q-Q plot and a slight football effect in the
# residuals vs. fitted values plot.
c(n$coefficients,summary(n)$adj.r.squared)
```

We can see from the Q-Q plot and the results of the Shapiro-Wilk test for normality that the residuals are approximately normal, and the residuals vs. fitted values plot shows the homoscedasticity assumption is not violated. It appears the most appropriate model among the given predictor variables is $y$ = 34.501651592 - 0.184978006$(x_2)$ - 0.002231404$(x_1^2)$ + 0.002987675$(x_2^2)$. However, we can see the adjusted-$r^2$ for the model is only `r summary(n)$adj.r.squared`, indicating that approximately `r 100*summary(n)$adj.r.squared` percent of the variation in the data is explained by the model. A better model may include variables other than the ones we started with (age and blood pressure), a higher-order polynomial, or a different type of model altogether (exponential, LOESS, etc.).

(b)

Model: $y$ = $\beta_0$ + $\beta_dx_d$ + $\beta_1x_1$ + $\epsilon$

$y$: response variable (body mass index)

$\beta_0$: intercept term

$\beta_d$: intercept term for $x_d$

$x_d$: coded variable for diabetes

$\beta_1$: intercept term for $x_1$

$x_1$: coded variable for age (from Problem 1(a))

$\epsilon$: error term

```{r Problem 1(b)}
dia<-final[-14,"diabetes"]
BMI<-lm(y~dia+x1)
anova(BMI)
# We can see neither diabetes nor age (x1) are significant at the
summary(BMI)       # alpha = 0.05 level (p = 0.7038, p = 0.1031).
# We can see the intercept term is significant at the alpha = 0.05 level (p < 0.00001),
shapiro.test(BMI$residuals) # but diabetes and age (x1) are not (p = 0.327, p = 0.103).
# The null hypothesis was not rejected (p = 0.4064) at the alpha = 0.05 level,
par(mfrow=c(1,2))             # so the normality assumption appears to be met.
qqnorm(BMI$residuals)
qqline(BMI$residuals)
plot(BMI$fitted.values,BMI$residuals)
abline(h=0)
# There is a slight variation in the Q-Q plot and a slight football effect in the
# residuals vs. fitted values plot.
pred<-data.frame(final[c("age","diabetes")],final["mass"],c(BMI$fitted.values[1:13],NA,BMI$fitted.values[14:49]),c(BMI$residuals[1:13],NA,BMI$residuals[14:49]))
names(pred)<-c("Age","Diabetes","BMI","Predicted BMI","BMI - Pred")
plot(pred[pred["Diabetes"]=="pos" & pred["BMI"]!=0,"Age"],pred[pred["Diabetes"]=="pos" & pred["BMI"]!=0,"BMI"],col="red",pch=0,xlim=c(20,73),ylim=c(19,49),xlab="Age",ylab="Actual BMI")
points(pred[pred["Diabetes"]=="neg" & pred["BMI"]!=0,"Age"],pred[pred["Diabetes"]=="neg" & pred["BMI"]!=0,"BMI"],col="green")
plot(pred[pred["Diabetes"]=="pos" & pred["BMI"]!=0,"Age"],pred[pred["Diabetes"]=="pos" & pred["BMI"]!=0,"Predicted BMI"],col="red",pch=0,xlim=c(20,73),ylim=c(19,49),xlab="Age",ylab="Predicted BMI")
points(pred[pred["Diabetes"]=="neg" & pred["BMI"]!=0,"Age"],pred[pred["Diabetes"]=="neg" & pred["BMI"]!=0,"Predicted BMI"],col="green")
legend(38.5,50,c("Positive (+)","Negative (-)"),title="Diabetes Level",col=c("red","green"),pch=c(0,1))
hist(pred[,"BMI - Pred"],freq=FALSE,main="",xlab="Predicted - Actual BMI")
lines(seq(min(pred[-14,"BMI - Pred"]),max(pred[-14,"BMI - Pred"]),length.out=100),dnorm(seq(min(pred[-14,"BMI - Pred"]),max(pred[-14,"BMI - Pred"]),length.out=100),0,sd(pred[-14,"BMI - Pred"])))
lines(density(pred[-14,"BMI - Pred"]),col="red",lty=2)
legend(-9.6,0.016,c("Normal","Kernel"),bg="white",col=c("black","red"),lty=c(1,2))
plot(pred[pred["Diabetes"]=="pos" & pred["BMI"]!=0,"Age"],pred[pred["Diabetes"]=="pos" & pred["BMI"]!=0,"BMI - Pred"],col="red",pch=0,xlim=c(21,73),ylim=c(-15,15),xlab="Age",ylab="Predicted - Actual")
points(pred[pred["Diabetes"]=="neg" & pred["BMI"]!=0,"Age"],pred[pred["Diabetes"]=="neg" & pred["BMI"]!=0,"BMI - Pred"],col="green")
abline(h=0)
c(BMI$coefficients,summary(BMI)$adj.r.squared)
```

We can see from the histogram, Q-Q plot, and the results of the Shapiro-Wilk test for normality that the residuals are approximately normal, and the residuals vs. fitted values plot shows the homoscedasticity assumption is not violated. It appears the most appropriate model among the given predictor variables is $y$ = 37.11208664 - 1.90585946$(x_d)$ - 0.12480081$(x_1)$. However, we can see the adjusted-$r^2$ for the model is only `r summary(BMI)$adj.r.squared`, indicating that approximately `r 100*summary(BMI)$adj.r.squared` percent of the variation in the data is explained by the model. A better model may include variables other than the ones we started with (diabetes and age), a higher-order polynomial, or a different type of model altogether (exponential, LOESS, etc.).

(c)

A randomized complete block design (RCBD) would be appropriate here. We assume the data are randomly collected for each age group, thus blocking by age.
```{r Problem 1(c)}
agef<-as.factor(cut.default(final[-14,"age"],breaks=3))
r<-lm(y~dia+agef)
anova(r)
# We can see the categorical variable for age (x1) is significant at the alpha = 0.05
shapiro.test(r$residuals) # level (p = 0.0009886), but diabetes is not (p = 0.6703056).
bartlett.test(r$residuals~dia)
bartlett.test(r$residuals~agef)
# None of the null hypotheses were rejected, so the normality and
par(mfrow=c(1,2))  # equal variance assumptions appear to be met.
qqnorm(r$residuals)
qqline(r$residuals)
plot(r$fitted.values,r$residuals)
abline(h=0)
# There is clustering and a slight football effect in the residuals vs. fitted values
# plot. We can see the three clusters corresponding to the three different age groups.
TukeyHSD(aov(y~dia+agef))$dia
```

We fail to reject the null hypothesis at the at the alpha = 0.05 level for the categorical variable for diabetes. There is insufficient evidence (p = `r anova(r)["dia","Pr(>F)"]`) that the mean BMI in patients with diabetes is different than the mean BMI in patients without diabetes. Further post-hoc analysis on the diabetes variable using Tukey's honestly significant difference (HSD) test confirms the difference (`r TukeyHSD(aov(y~dia+agef))$dia[,"diff"]`) in mean BMI between patients with diabetes and patients without diabetes is not significant.

(d)

A two-factor factorial design would be the most appropriate here, as there are two categorical variables, diabetes and age ($x_1$).
```{r Problem 1(d), message=FALSE}
c<-lm(y~dia*agef)
anova(c)
# We can see the categorical variable for age (x1) is significant at the
# alpha = 0.05 level (p = 0.00109), but diabetes and the interaction term between
shapiro.test(c$residuals) # diabetes and age are not (p = 0.67172, p = 0.45214).
bartlett.test(c$residuals~dia)
bartlett.test(c$residuals~agef)
library(car)
leveneTest(c)
# None of the null hypotheses were rejected, so the normality and
par(mfrow=c(1,2))  # equal variance assumptions appear to be met.
qqnorm(c$residuals)
qqline(c$residuals)
plot(c$fitted.values,c$residuals)
abline(h=0)
# There is a slight variation in the Q-Q plot and a megaphone/football effect in the
# residuals vs. fitted values plot.
par(mfrow=c(1,2))
interaction.plot(dia,agef,y)
interaction.plot(agef,dia,y,ylab="")
# The only pair of levels that appear to intersect in the interaction plot are the positive
# and negative lines between the "(20.9,38]" and "(38,55]" levels of age. However, we can
# see that the "(20.9,38]" and "(55,72.1]" lines between the negative and positive levels
# of diabetes are clearly not parallel. This could mean these levels of diabetes
TukeyHSD(aov(y~dia*agef)) # and age are related or associated with each other.
```

We fail to reject the null hypothesis at the at the alpha = 0.05 level for the interaction term between diabetes and age ($x_1$). There is insufficient evidence (p = 0.4521316) that the interaction between diabetes and age is significant. Further post-hoc analysis using Tukey's honestly significant difference (HSD) test shows the "(55,72.1]" level of age is significantly different than both the "(20.9,38]" (p = 0.012772) and "(38,55]" (p = 0.0007221608) levels. We can also see the interaction between the "(55,72.1]" level of age at the negative level of diabetes and the "(38,55]" level of age at the positive level of diabetes is significant (p = 0.01185704).

## Problem 2

|  |     |   |Time Periods|       |          |
|-:|:---:|:--:|:--------:|:------:|:--------:|
| |  1   |  2   |  3   |    4     |    5
|1|A=15.2|B=33.8|C=13.4|  D=27.4  |  E=29.1
|2|B=16.5|C=26.5|D=18.2|  E=25.8  |  A=22.7
|3| C=12 |D=31.4| E=17 |  A=31.5  |**B**=30.2
|4|D=10.8|E=34.2|A=19.5|**B**=27.2|**C**=21.6
|5|E=12.3|A=31.7|B=17.1|**C**=27.3|**D**=23.8
```{r Problem 2}
rlt<-c(15.2,33.8,13.4,27.4,29.1,16.5,26.5,18.2,25.8,22.7,12,31.4,17,31.5,30.2,10.8,34.2,19.5,27.2,21.6,12.3,31.7,17.1,27.3,23.8)
int<-rep(1:5,each=5)
tp<-rep(1:5,5)
seq<-as.factor(c("A","B","C","D","E","B","C","D","E","A","C","D","E","A","B","D","E","A","B","C","E","A","B","C","D"))
ls<-lm(rlt~seq+int+tp)
anova(ls)
# We can see that none of the variables in the model are significant at the alpha = 0.05
shapiro.test(ls$residuals)              # level (p = 0.86917, p = 0.85667, p = 0.07058).
bartlett.test(ls$residuals~int)
bartlett.test(ls$residuals~tp)
# The null hypothesis for the Shapiro-Wilk test is rejected at the at the
# alpha = 0.05 level (p = 0.01296). The normality assumption is clearly
# violated and we should consider a transformation of the data.
lnrlt<-log(rlt) # Natural logarithmic transformation of response variable
lnls<-lm(lnrlt~seq+int+tp) # New model
anova(lnls)
# We can see the time period variable is significant at the alpha = 0.05
# level (p = 0.02712), but the sequence and intersection variables are
shapiro.test(lnls$residuals)         # not (p = 0.84711, p = 0.81816).
bartlett.test(lnls$residuals~int)
bartlett.test(lnls$residuals~tp)
yl<-vector() # Levene's test
for(i in c("A","B","C","D","E")) yl[seq==i]<-abs(lnrlt[seq==i]-median(lnrlt[seq==i]))
l<-lm(yl~seq)
anova(l)["Pr(>F)"]
# We should exercise some caution here as the null hypothesis for the Shapiro-Wilk test for
par(mfrow=c(1,2)) # normality is nearly rejected at the alpha = 0.05 level (p = 0.05148).
qqnorm(lnls$residuals)
qqline(lnls$residuals)
plot(lnls$fitted.values,lnls$residuals)
abline(h=0)
# There is a slight variation in the Q-Q plot and a slight reverse megaphone effect in
# the residuals vs. fitted values plot.
```

## Problem 3

We have to use defining relation (i) I = ABCD = BCE because this problem is a $2^{5-2}$ fractional factorial and (i) is the only one of the two that is only in terms of the first (5-2) = 3 factors, A, B, and C (since D = ABC and E = BC). If we used defining relation (ii) I = ABCDE = ABCD, we see D = ABC, like in (i), but E = ABCD, which contains a term (D) other than A, B, and C. Additionally, E = ABCD = ABC(ABC) = I, so E would be confounding the identity column and also would not have an equal number of observations per level.
```{r Problem 3}
A<-as.factor(rep(c(-1,1),4))
B<-as.factor(rep(c(-1,1),2,each=2))
C<-as.factor(rep(c(-1,1),each=4)) # I = ABCD -> D = ABC
D<-as.factor(as.numeric(as.character(A))*as.numeric(as.character(B))*as.numeric(as.character(C)))
E<-as.factor(as.numeric(as.character(B))*as.numeric(as.character(C))) # I = BCE -> E = BC
qrei<-c(7.93,17.55,9.2,5.82,8.68,7.8,6.4,26.05) # e, ade, bd, ab, cd, ac, bce, abcde
q<-lm(qrei~(A+B+C+D+E)^5)
anova(q)
qq<-qqnorm(abs(q$effects[-1]),type="n") # Remove variables
text(qq$x,qq$y,labels=names(abs(q$effects[-1])))
abline(h=6.6,lty=2) # Arbitrary cutoff
legend(-1.45,12,"x = 6.6",lty=2)
s<-lm(qrei~A+D+E) # New model
anova(s)
# We can see all three factors (A, D, and E) in the reduced model are significant at
par(mfrow=c(1,3))  # the alpha = 0.05 level (p = 0.04794, p = 0.01948, p = 0.04083).
plot.design(data.frame(A,B,C,D,E,qrei))
interaction.plot(A,D,qrei,ylab="")
interaction.plot(D,A,qrei,ylab="")
par(mfrow=c(2,2))
interaction.plot(A,E,qrei)
interaction.plot(E,A,qrei,ylab="")
interaction.plot(D,E,qrei)
interaction.plot(E,D,qrei,ylab="")
# There is intersection in the interaction plots for the A*D and A*E interaction terms.
# The interaction plot for the D*E interaction term does not appear to have any
# intersection, but the lines are clearly not parallel. This could mean factors A,
shapiro.test(s$residuals) # D, and E are related or associated with each other.
bartlett.test(s$residuals~A)
bartlett.test(s$residuals~B)
bartlett.test(s$residuals~C)
bartlett.test(s$residuals~D)
bartlett.test(s$residuals~E)
# We should exercise caution here as the null hypotheses for the Bartlett's test for
# factors A and E were rejected at the alpha = 0.05 level (p = 0.02154, p = 0.04238).
par(mfrow=c(1,2))
qqnorm(s$residuals)
qqline(s$residuals)
plot(s$fitted.values,s$residuals)
abline(h=0)
# There appears to be some variation in the Q-Q plot and a megaphone effect in the
# residuals vs. fitted values plot. We should consider a transformation of the data.
lnqrei<-log(qrei) # Natural logarithmic transformation of response variable
t<-lm(lnqrei~A+D+E) # New model
anova(t)
# We can see all three factors in the logarithm-transformed model are significant at the
shapiro.test(t$residuals)  # alpha = 0.05 level (p = 0.03888, p = 0.00689, p = 0.02628).
bartlett.test(t$residuals~A)
bartlett.test(t$residuals~B)
bartlett.test(t$residuals~C)
bartlett.test(t$residuals~D)
bartlett.test(t$residuals~E)
# None of the null hypotheses were rejected, so the normality and
par(mfrow=c(1,2))  # equal variance assumptions appear to be met.
qqnorm(t$residuals)
qqline(t$residuals)
plot(t$fitted.values,t$residuals)
abline(h=0)
# There appears to be a slighter variation in the Q-Q plot. We can also see the magnitude
# of the megaphone effect in the residuals vs. fitted values plot has decreased.
```