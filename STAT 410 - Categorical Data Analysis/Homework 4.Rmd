---
title: "Homework 4"
author: "Charles Hwang"
date: "3/2/2022"
output: pdf_document
---
Charles Hwang

Dr. Whalen

STAT 410-001

2 March 2022

## Problem 4.4

```{r Problem 4.4}
rm(list=ls())
o0<-(exp(-3.866+0.397*0)/(1+exp(-3.866+0.397*0)))/(1-exp(-3.866+0.397*0)/(1+exp(-3.866+0.397*0)))
o2<-(exp(-3.866+0.397*2)/(1+exp(-3.866+0.397*2)))/(1-exp(-3.866+0.397*2)/(1+exp(-3.866+0.397*2)))
o4<-(exp(-3.866+0.397*4)/(1+exp(-3.866+0.397*4)))/(1-exp(-3.866+0.397*4)/(1+exp(-3.866+0.397*4)))
o5<-(exp(-3.866+0.397*5)/(1+exp(-3.866+0.397*5)))/(1-exp(-3.866+0.397*5)/(1+exp(-3.866+0.397*5)))
or<-data.frame(c(o2/o0,o4/o0,o5/o0),c("",o4/o2,o5/o2),c("","",o5/o4))
names(or)<-c("0","2","4")
row.names(or)<-c("2","4","5")
or
```

We can see the odds of heart disease increases with snoring level, as previously expected. Specifically, those who "occasionally" snore are approximately `r or["2","0"]` times more likely to have heart disease than those who "never" snore, those who snore "nearly every night" are approximately `r or["4","0"]` times more likely to have heart disease than those who "never" snore, those who snore every night are approximately `r or["5","0"]` times more likely to have heart disease than those who "never" snore, those who snore "nearly every night" are approximately `r or["4","2"]` times more likely to have heart disease than those who "occasionally" snore, those who snore "every night" are approximately `r or["5","2"]` times more likely to have heart disease than those who "occasionally" snore, and those who snore "every night" are approximately `r or["5","4"]` times more likely to have heart disease than those who snore "nearly every night".

## Problem 4.8

```{r Problem 4.8, message=FALSE}
hc<-read.table("http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat",header=TRUE)
cw<-glm(y~weight,family=binomial(link="logit"),data=hc)
exp(cw$coefficients["weight"]*0.1)                       # Problem 4.8(b)
# For every 0.1 kilogram increase in weight, the odds of a crab having at
# least one satellite crab are multiplied by approximately 1.199032 times.
wt<-xtabs(~hc$y+as.numeric(cw$fitted.values>mean(hc$y))) # Problem 4.8(c)
wt
wt["1","1"]/sum(wt["1",])
wt["0","0"]/sum(wt["0",])
# The probability of a crab having at least one satellite crab given that this model
# predicted it to have at least one satellite crab is approximately 0.6126126. The
# probability of a crab not having at least one satellite crab given that this model
# predicted it to not have at least one satellite crab is approximately 0.7258065.
library(pROC)                                            # Problem 4.8(d)
plot.roc(roc(y~cw$fitted.values,data=hc),legacy.axes=TRUE)
auc(roc(y~cw$fitted.values,data=hc))
```

We can see the area under the curve is approximately `r auc(roc(y~cw$fitted.values,data=hc))`. There is approximately a `r 100*auc(roc(y~cw$fitted.values,data=hc))` percent probability the predictions and outcomes are concordant.

## Problem 4.9

```{r Problem 4.9}
cc<-glm(y~factor(color,levels=c(4,1:3)),family=binomial(link="logit"),data=hc) # Problem 4.9(a)
cc$coefficients
# logit(y-hat) = -0.7621401 + 1.8607523(c_1) + 1.73815(c_2) - 1.1298648(c_3)
# The variables for the first color would be c_1=1 and c_2=c_3=0, and the resulting
# probability is logit(y-hat)=-0.7621401+1.8607523(1)+1.73815(0)-1.1298648(0)=1.0986123 ->
# e^1.0986123 / (1 + e^1.0986123) = 0.75.
# The variables for the fourth color would be c_1 = c_2 = c_3 = 0, and the resulting
# probability is logit(y-hat)=-0.7621401+1.8607523(0)+1.73815(0)-1.1298648(0)=-0.7621401 ->
# e^-0.76214 / (1 + e^-0.76214) = 0.3182 = 7/22.
exp(cc$coefficients["factor(color, levels = c(4, 1:3))1"])
# The odds of a medium light crab has at least one satellite crab are approximately
# 6.428571 times of the odds of a dark crab having at least one satellite crab.
anova(cc,test="LRT")                                                           # Problem 4.9(b)
# We reject H0 at the alpha = 0.05 level. There is sufficient evidence (p = 0.003346919)
# that color as a nominal-scale factor has a statistically significant effect in the model.
ccq<-glm(y~color,family=binomial(link="logit"),data=hc)                        # Problem 4.9(c)
ccq$coefficients
# logit(y-hat) = 2.3634527 - 0.7146794(c), where c = 1 (ml), 2 (m), 3 (md), 4 (d)
exp(ccq$coefficients["color"])
# For each darker level of color, the odds are multiplied by approximately 0.489349 times.
anova(ccq,test="LRT")
# We reject H0 at the alpha = 0.05 level. There is sufficient evidence (p = 0.0004156143)
# that color as a quantitative variable has a statistically significant effect in the model.
# One advantage for this particular model with the quantitative color          # Problem 4.9(d)
# variable is that having only one degree of freedom "shrinks" the chi-square distribution
# so that the critical value for the test statistic is lower and the null hypothesis for the
# variable having no effect is more easily rejected. However, one disadvantage is that since
# there are more than two levels for color, it is unknown whether the designated values
# b_c = 1, 2, 3, 4 are statistically accurate for a single coefficient. In other words, the
# distance between the values b_c = 1, 2, 3, 4 are the same, implying the differences in
# probabilities between each level are the same, when that is not necessarily the case.
cwc<-glm(y~weight+color,family=binomial(link="logit"),data=hc)                 # Problem 4.9(e)
sd(hc$weight)*cwc$coefficients["weight"]
sd(hc$color)*cwc$coefficients["color"]
```

We can see that a one-$s_w$ increase in weight is estimated to have approximately `r abs((sd(hc$weight)*cwc$coefficients["weight"])/(sd(hc$color)*cwc$coefficients["color"]))` times the effect of a one-$s_c$ increase in color, adjusting for the other variable.

## Problem 4.12

```{r Problem 4.12, warning=FALSE}
MBTI<-read.table("http://users.stat.ufl.edu/~aa/cat/data/MBTI.dat",header=TRUE)
glm(drink/n~EI+SN+TF+JP,family=binomial(link="logit"),weights=n,data=MBTI)$coefficients
```

logit$(\hat{\pi}(x))=-2.114047-0.5550115\beta_{EI}-0.4291508\beta_{SN}+0.6873349\beta_{TF}+0.2022295\beta_{JP}$

$\hat{\pi}(x)$: probability of drinking alcohol frequently

$\beta_{EI}$: binary variable for **E**xtroversion/**I**ntroversion (0 for E, 1 for I)

$\beta_{SN}$: binary variable for **S**ensing/i**N**tuition (0 for N, 1 for S)

$\beta_{TF}$: binary variable for **T**hinking/**F**eeling (0 for F, 1 for T)

$\beta_{JP}$: binary variable for **J**udging/**P**erceiving (0 for J, 1 for P)

Looking at the model and the signs of the coefficients, we can see that in order to maximize $\hat{\pi}(x)$, the combination of ENTP should be chosen and thus it has the highest estimated probability of drinking alcohol frequently.

## Problem 4.16

```{r Problem 4.16}
st<-read.table("http://users.stat.ufl.edu/~aa/cat/data/SoreThroat.dat",header=TRUE)
t<-glm(Y~D*T,family=binomial(link="logit"),data=st) # Problem 4.16(a)
t$coefficients
# logit(y-hat) = 0.04978674 + 0.02847802(b_D) - 4.47224144(b_T) + 0.07460127(b_D)(b_T)
# logit(y-hat|t = 1) = 0.04978674+0.02847802(b_D)-4.47224144(1)+0.07460127(b_D)(1)=  # (i)
# logit(y-hat|t = 1) = -4.4224547 + 0.10307929(b_D)
exp(sum(t$coefficients[c("D","D:T")]))
# For every additional 1 minute increase in the duration of the surgery, the odds of
# the patient experiencing a sore throat upon waking up are multiplied by approximately
# 1.108579 times, given that a tracheal tube was used to secure the airway.
# logit(y-hat|t = 0) = 0.04978674+0.02847802(b_D)-4.47224144(0)+0.07460127(b_D)(0)=  # (ii)
# logit(y-hat|t = 0) = 0.04978674 + 0.02847802(b_D)
exp(sum(t$coefficients["D"]))
# For every additional 1 minute increase in the duration of the surgery, the odds of
# the patient experiencing a sore throat upon waking up are multiplied by approximately
# 1.028887 times, given that a laryngeal mask airway was used to secure the airway.
summary(t)$coefficients
# We fail to reject H0 at the alpha = 0.05 level. There is insufficient
# evidence (p = 0.19656821) that an interaction term is significant in the model. We can
# also see the weight of the coefficient for the interaction term is relatively small.
cor(st$Y,t$fitted)                                   # Problem 4.16(b)
cor(st$Y,glm(Y~D+T,family=binomial(link="logit"),data=st)$fitted)
```

We can see the correlation of the models with and without the interaction term $\beta_D\beta_T$ are nearly the same. The correlation is improved by approximately `r cor(st$Y,t$fitted)-cor(st$Y,glm(Y~D+T,family=binomial(link="logit"),data=st)$fitted)` in the model with the interaction terms.

## Problem 4.19

```{r Problem 4.19}
# If using the equation in the textbook answers (page 354), the code would instead be:
# glm(y~width*factor(color,levels=c(4,1:3)),family=binomial(link="logit"),data=hc)
wc<-glm(y~width*factor(color),family=binomial(link="logit"),data=hc) # Problem 4.19(a)
wc$coefficients
# logit(y-hat) = -1.75260875 + 0.10600046(b_w) - 8.28735421(b_2) - 19.76545392(b_3)
# - 4.10122117(b_4) + 0.31287057(b_w)(b_2) + 0.75236820(b_w)(b_3) + 0.09442916(b_w)(b_4)
# logit(y-hat|c = 1) = -1.75260875 + 0.10600046(b_w)
a1<-wc$coefficients["(Intercept)"]
# logit(y-hat|c = 2) = -1.75260875 + 0.10600046(b_w) - 8.28735421(1) + 0.31287057(b_w)(1)
# logit(y-hat|c = 2) = -10.03996 + 0.41887103(b_w)
a2<-sum(wc$coefficients[c("(Intercept)","factor(color)2")])
b2<-wc$coefficients[c("width","width:factor(color)2")]
# logit(y-hat|c = 3) = -1.75260875 + 0.10600046(b_w) - 19.76545392(1) + 0.75236820(b_w)(1)
# logit(y-hat|c = 3) = -21.51806267 + 0.85836866(b_w)
a3<-sum(wc$coefficients[c("(Intercept)","factor(color)3")])
b3<-wc$coefficients[c("width","width:factor(color)3")]
# logit(y-hat|c = 4) = -1.75260875 + 0.10600046(b_w) - 4.10122117(1) + 0.09442916(b_w)(1)
# logit(y-hat|c = 4) = -5.85382992 + 0.20042962(b_w)
a4<-sum(wc$coefficients[c("(Intercept)","factor(color)4")])
b4<-wc$coefficients[c("width","width:factor(color)4")]
plot(c(hc[hc$color==1,"width"],hc[hc$color==2,"width"],hc[hc$color==3,"width"],hc[hc$color==4,"width"]),c(hc[hc$color==1,"y"],hc[hc$color==2,"y"],hc[hc$color==3,"y"],hc[hc$color==4,"y"]),col=c("gray96","gray64","gray32","black"),xlab="Shell Width (cm)",ylab="Predicted Probability of Having Satellite(s)",main="Problem 4.19(a) - Plot of Logistic Prediction Equations")
curve(exp(a1+wc$coefficients["width"]*x)/(1+exp(a1+wc$coefficients["width"]*x)),col="gray93",add=TRUE)
curve(exp(a2+sum(b2)*x)/(1+exp(a2+sum(b2)*x)),col="gray62",add=TRUE)
curve(exp(a3+sum(b3)*x)/(1+exp(a3+sum(b3)*x)),col="gray31",add=TRUE)
curve(exp(a4+sum(b4)*x)/(1+exp(a4+sum(b4)*x)),add=TRUE)
abline(h=0.5,lty=2)
legend(30.6,0.45,title="Shell Color",c("Med. Light","Medium","Med. Dark","Dark"),col=c("gray93","gray62","gray31","black"),lty=1,pch=1)
exp(wc$coefficients["width"])
# For every 1 centimeter increase in shell width, the odds of a medium light crab
# having at least one satellite crab are multiplied by approximately 1.111822 times.
exp(sum(b2))
# For every 1 centimeter increase in shell width, the odds of a medium crab having
# at least one satellite crab are multiplied by approximately 1.520244 times.
exp(sum(b3))
# For every 1 centimeter increase in shell width, the odds of a medium dark crab
# having at least one satellite crab are multiplied by approximately 2.359309 times.
exp(sum(b4))
# For every 1 centimeter increase in shell width, the odds of a dark crab having
# at least one satellite crab are multiplied by approximately 1.221928 times.
cor(hc$y,wc$fitted)                                                   # Problem 4.16(b)
cor(hc$y,glm(y~width+factor(color),family=binomial(link="logit"),data=hc)$fitted)
```

We can see the correlation of the models with and without the interaction terms $\beta_w\beta_2$, $\beta_w\beta_3$, and $\beta_w\beta_4$ are about the same. The correlation is improved by approximately `r cor(hc$y,wc$fitted)-cor(hc$y,glm(y~width+factor(color),family=binomial(link="logit"),data=hc)$fitted)` in the model with the interaction terms.

## Problem 4.21

Table 4.4 (page 110) can be constructed using `R`:

```{r Problem 4.21}
wc$fitted.values[6]<-0.50000001 # One crab in Table 4.4 was misfitted for some reason
Actual<-factor(hc$y,levels=1:0)
"Prediction, pi_0=0.50"<-factor(as.numeric(wc$fitted.values>0.5),levels=1:0)
xtabs(~Actual+`Prediction, pi_0=0.50`)
xtabs(~Actual+`Prediction, pi_0=0.50`)["1","1"]/sum(xtabs(~Actual+`Prediction, pi_0=0.50`)["1",])
xtabs(~Actual+`Prediction, pi_0=0.50`)["0","0"]/sum(xtabs(~Actual+`Prediction, pi_0=0.50`)["0",])
```

The probability of a crab having at least one satellite crab given that this model predicted it to have at least one satellite crab (sensitivity) is approximately `r xtabs(~Actual+factor(as.numeric(wc$fitted.values>0.5),levels=1:0))["1","1"]/sum(xtabs(~Actual+factor(as.numeric(wc$fitted.values>0.5),levels=1:0))["1",])`. The probability of a crab not having at least one satellite crab given that this model predicted it to not have at least one satellite crab (specificity) is approximately `r xtabs(~Actual+factor(as.numeric(wc$fitted.values>0.5),levels=1:0))["0","0"]/sum(xtabs(~Actual+factor(as.numeric(wc$fitted.values>0.5),levels=1:0))["0",])`.