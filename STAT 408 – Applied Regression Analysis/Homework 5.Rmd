---
title: "Homework 5"
author: "Charles Hwang"
date: "11/30/2022"
output: pdf_document
---
Charles Hwang

Dr. Xi

STAT 408-001

2022 November 30

## Problem 1

```{r Problem 1}
rm(list=ls())
g<-read.csv("/Users/newuser/Desktop/Notes/Graduate/STAT 408 - Applied Regression Analysis/teengamb.csv")
```

### Problems 1a-1b

```{r Problem 1a-1b}
plot(gamble~income,data=g[g$sex==0,],pch=2,col="blue",main="Gambling vs. Income by Sex with Linear Regression Lines")
points(gamble~income,data=g[g$sex==1,],col="red") # Problem 1a
summary(lm(gamble~income+sex,data=g))             # Problem 1b
c<-lm(gamble~income+sex,data=g)$coefficients
abline(c["(Intercept)"]+0*c["sex"],c["income"],col="blue")
abline(c["(Intercept)"]+1*c["sex"],c["income"],col="red")
legend("topleft",c("Male","Female"),col=c("blue","red"),pch=2:1,lty=1)
```

### Problem 1c

```{r Problem 1c, message=FALSE, warning=FALSE}
library(Matching)
library(rgenoud)
set.seed(2022)
m<-GenMatch(g$sex,g$income,ties=FALSE,print.level=0)$matches[,1:2] # Lecture 14, Slide 17
t(m)
matrix((1:nrow(g))[-unique(sort(m))],nrow=1) # Observation numbers of unmatched cases
```

We can see there are `r nrow(m)` matched pairs and `r length((1:nrow(g))[-unique(sort(m))])` unmatched cases out of `r nrow(g)`.

### Problem 1d

```{r Problem 1d}
d<-g$gamble[m[,1]]-g$gamble[m[,2]]
t.test(d)
```

We can see from the results of the one-sample *t*-test that the difference in annual gambling expenditure for the matched pairs is approximately £`r abs(t.test(d)$estimate)` and that this difference is significant at the $\alpha=0.05$ level. There is sufficient evidence ($t=$ `r t.test(d)$statistic`, $p=$ `r t.test(d)$p.value`) that the difference is nonzero.

### Problem 1e

```{r Problem 1e}
plot(d~g$gamble[m[,1]],ylim=c(-60,20),xlab="Weekly Income (£)",ylab="Difference in Gambling Expenditure",main="Difference in Gambling Expenditure vs. Weekly Income")
points((g$gamble[m[,1]])[d>0],d[d>0],col="red",pch=19)
abline(h=0)
```

We can see the female spent *more* on gambling annually than the male in `r 100*sum(d>0)/nrow(m)` percent ($\frac{3}{19}$) of the pairs.

### Problem 1f

The conclusions from the linear model and the matched pair approach generally agree with one another. We can see that both suggest that males tend to have a higher gambling expenditure than females, holding all other variables constant. This is consistent with similar findings in Homework 2, Problems 2a and 2f and Homework 3, Problems 3a and 3b.

## Problem 2

```{r Problem 2}
i<-read.csv(row.names=1,file="/Users/newuser/Desktop/Notes/Graduate/STAT 408 - Applied Regression Analysis/infmort.csv")
```

### Problem 2a

```{r Problem 2a}
for(j in 1:length(i)){print(c(names(i)[j],typeof(i[,j])))}
lapply(apply(i,2,unique)[c("region","oil")],sort)
```

We can see the `income` and `mortality` variables are continuous in this dataset, while the `region` and `oil` variables are categorical with `r length(unique(i$region))` and `r length(unique(i$oil))` levels respectively.

### Problem 2b

```{r Problem 2b}
i$region<-as.factor(i$region)
i$oil<-as.factor(i$oil)
summary(lm(mortality~.,data=i))
```

We can see this model has an adjusted $r^2$ of approximately `r summary(lm(mortality~.,data=i))$adj.r.squared`. We can also see that the intercept term and all variables in the model except for `income` ($p=$ `r summary(lm(mortality~.,data=i))$coefficients["income","Pr(>|t|)"]`) are significant at the $\alpha=0.05$ level.

Interpretation of $\beta_0$ (intercept term): We estimate a hypothetical country in Africa (baseline region) with a per-capita income of \$0 (which would not make sense) and does not export oil has an infant mortality rate of approximately `r summary(lm(mortality~.,data=i))$coefficients["(Intercept)","Estimate"]` per capita.

Interpretation of $\beta_{Am}$ (coefficient for the Americas region dummy variable): We estimate there is approximately a `r abs(summary(lm(mortality~.,data=i))$coefficients["regionAmericas","Estimate"])`-per-capita **decrease** in infant mortality if a country is located in the Americas as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_{Asia}$ (coefficient for Asia region dummy variable): We estimate there is approximately a `r abs(summary(lm(mortality~.,data=i))$coefficients["regionAsia","Estimate"])`-per-capita **decrease** in infant mortality if a country is located in Asia as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_E$ (coefficient for Europe region dummy variable): We estimate there is approximately a `r abs(summary(lm(mortality~.,data=i))$coefficients["regionEurope","Estimate"])`-per-capita **decrease** in infant mortality if a country is located in Europe as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_I$ (coefficient for income-per-capita variable): We estimate there is approximately a `r abs(summary(lm(mortality~.,data=i))$coefficients["income","Estimate"])`-per-capita **decrease** in infant mortality for every \$1-per-capita increase in income, holding all other variables constant.

Interpretation of $\beta_X$ (coefficient for oil exports dummy variable): We estimate there is approximately a `r summary(lm(mortality~.,data=i))$coefficients["oiloil exports","Estimate"]`-per-capita **increase** in infant mortality in countries that export oil compared to countries that do not export oil, holding all other variables constant.

### Problem 2c

```{r Problem 2c}
x<-lm(mortality~.+income*region+income*oil,data=i)
summary(x)
```

We can see this model has a greater adjusted $r^2$ than the model from problem 2b (`r summary(x)$adj.r.squared` vs. `r summary(lm(mortality~.,data=i))$adj.r.squared`). We can also see that the intercept term and all variables in the model are significant at the $\alpha=0.05$ level.

Interpretation of $\beta_0$ (intercept term): We estimate a hypothetical country in Africa (baseline region) with a per-capita income of \$0 (which would not make sense) and does not export oil has an infant mortality rate of approximately `r summary(x)$coefficients["(Intercept)","Estimate"]` per capita.

Interpretation of $\beta_{Am}$ (coefficient for the Americas region dummy variable): We estimate there is approximately a `r abs(summary(x)$coefficients["regionAmericas","Estimate"])`-per-capita **decrease** in infant mortality if a country is located in the Americas as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_{Asia}$ (coefficient for Asia region dummy variable): We estimate there is approximately a `r abs(summary(x)$coefficients["regionAsia","Estimate"])`-per-capita **decrease** in infant mortality if a country is located in Asia as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_E$ (coefficient for Europe region dummy variable): We estimate there is approximately a `r abs(summary(x)$coefficients["regionEurope","Estimate"])`-per-capita **decrease** in infant mortality if a country is located in Europe as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_I$ (coefficient for income-per-capita variable): We estimate there is approximately a `r abs(summary(x)$coefficients["income","Estimate"])`-per-capita **decrease** in infant mortality for every \$1-per-capita increase in income, holding all other variables constant.

Interpretation of $\beta_X$ (coefficient for oil exports dummy variable): We estimate there is approximately a `r abs(summary(x)$coefficients["oiloil exports","Estimate"])`-per-capita **decrease** in infant mortality in countries that export oil compared to countries that do not export oil, holding all other variables constant.

Interpretation of $\beta_{AmI}$ (interaction term between the Americas region and income): If a country is located in the Americas, we estimate there is approximately a `r summary(x)$coefficients["regionAmericas:income","Estimate"]`-per-capita **increase** in infant mortality for every \$1-per-capita increase in income as opposed to if it were located in Africa, holding all other variables constant.

Interpretation of $\beta_{AsiaI}$ (interaction term between Asia region and income): If a country is located in Asia, we estimate there is approximately a `r summary(x)$coefficients["regionAsia:income","Estimate"]`-per-capita **increase** in infant mortality for every \$1-per-capita increase in income as opposed to if it were located in Africa, holding all other variables constant.

Interpretation of $\beta_{EI}$ (interaction term between Europe region and income): If a country is located in Europe, we estimate there is approximately a `r summary(x)$coefficients["regionEurope:income","Estimate"]`-per-capita **increase** in infant mortality for every \$1-per-capita increase in income as opposed to if it were located in Africa, holding all other variables constant.

Interpretation of $\beta_{IX}$ (interaction term between income and oil exports): If a country exports oil, we estimate there is approximately a `r summary(x)$coefficients["income:oiloil exports","Estimate"]` **increase** per capita in infant mortality for every \$1-per-capita increase in income compared to countries that do not export oil, holding all other variables constant.

### Problem 2d

```{r Problem 2d}
par(mfrow=c(1,2))
plot(x$residuals~x$fitted.values,xlim=c(0,390),main="Residuals vs. Fitted Values")
abline(h=0)
qqnorm(x$residuals)
qqline(x$residuals)
par(mfrow=c(2,2))
hist(log(i$income))
hist(log(i$mortality))
plot(mortality~income,data=i)
plot(log(mortality)~log(income),data=i)
```

We can see the model in Problem 2c does not satisfy the constant variance assumption. There is a megaphone effect in the residuals vs. fitted values plot and there are tails at each of the ends of the Q-Q plot which additionally violates the normality assumption.

After looking at the data, I believe a log-log transformation on the two continuous variables (`mortality` and `oil`) may be appropriate because both variables are very right-skew.

```{r Problem 2dt}
xt<-lm(log(mortality)~log(income)+region+oil+income*region+income*oil,data=i)
par(mfrow=c(1,1))
plot(xt$residuals~xt$fitted.values)
abline(h=0)
qqnorm(xt$residuals)
qqline(xt$residuals)
```

The residuals vs. fitted values plot still appears to have a slight megaphone effect which suggests there may be some heteroscedasticity. The Q-Q plot looks much better, although there are still slight tails at each end. However, these assumptions no longer appear to be badly violated.

### Problem 2e

```{r Problem 2e}
summary(xt)
```

Interpretation of $\beta_{Am}$ (coefficient for the Americas region dummy variable): We estimate there is approximately a $e^{-0.4099345}-1=$ `r abs(100*(exp(summary(xt)$coefficients["regionAmericas","Estimate"])-1))` **percent decrease** in infant mortality per capita if a country is located in the Americas as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_{Asia}$ (coefficient for Asia region dummy variable): We estimate there is approximately a $e^{-0.7345388}-1=$ `r abs(100*(exp(summary(xt)$coefficients["regionAsia","Estimate"])-1))` **percent decrease** in infant mortality per capita if a country is located in Asia as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_E$ (coefficient for Europe region dummy variable): We estimate there is approximately a $e^{-0.6451988}-1=$ `r abs(100*(exp(summary(xt)$coefficients["regionEurope","Estimate"])-1))` **percent decrease** in infant mortality per capita if a country is located in Europe as opposed to Africa, holding all other variables constant.

Interpretation of $\beta_X$ (coefficient for oil exports dummy variable): We estimate there is approximately a $e^{-0.2984385}-1=$ `r abs(100*(exp(summary(xt)$coefficients["oiloil exports","Estimate"])-1))` **percent decrease** in infant mortality per capita in countries that export oil as opposed to if it did not export oil, holding all other variables constant.

## Problem 3

### Problem 3a

$L(\beta)=\Pi_{i=1}^4p^{y_i}(1-p_{y_i})^{1-y_i}\hfill{n=4}$

$L(\beta)=p_{y_1}p_{y_2}(1-p_{y_3})(1-p_{y_4})\hfill{y_1=1,y_2=1,y_3=0,y_4=0}$

$p_{y_1}=P(Y_1=1)=\frac{1}{1+e^{-(\beta_0+\beta_14)}}\hfill{x_1=4,y_1=1}$

$p_{y_2}=P(Y_2=1)=\frac{1}{1+e^{-(\beta_0+\beta_13)}}\hfill{x_2=3,y_2=1}$

$1-p_{y_3}=1-P(Y_3=1)=1-\frac{1}{1+e^{-(\beta_0+\beta_12)}}\hfill{x_3=2,y_3=0}$

$1-p_{y_4}=1-P(Y_4=1)=1-\frac{1}{1+e^{-(\beta_0+\beta_11)}}\hfill{x_4=1,y_4=0}$

$L(\beta)=\frac{1}{1+e^{-(\beta_0+4\beta_1)}}\frac{1}{1+e^{-(\beta_0+3\beta_1)}}(1-\frac{1}{1+e^{-(\beta_0+2\beta_1)}})(1-\frac{1}{1+e^{-(\beta_0+\beta_1)}})$

$L(\beta)=\frac{e^{-(2\beta_0+3\beta_1)}}{(1+e^{-(\beta_0+4\beta_1)})(1+e^{-(\beta_0+3\beta_1)})(1+e^{-(\beta_0+2\beta_1)})(1+e^{-(\beta_0+\beta_1)})}$

### Problem 3b

$\ln(L(\beta))=\Sigma_{i=1}^4[y_i\ln p+(1-y_i)\ln(1-p)]\hfill{n=4}$

$\ln(L(\beta))=\ln p_{y_1}+\ln p_{y_2}+\ln(1-p_{y_3})+\ln(1-p_{y_4})\hfill{y_1=1,y_2=1,y_3=0,y_4=0}$

$\ln(L(\beta))=\ln\frac{1}{1+e^{-(\beta_0+4\beta_1)}}+\ln\frac{1}{1+e^{-(\beta_0+3\beta_1)}}+\ln(1-\frac{1}{1+e^{-(\beta_0+2\beta_1)}})+\ln(1-\frac{1}{1+e^{-(\beta_0+\beta_1)}})$

$\ln(L(\beta))=-[\ln(1+e^{-(\beta_0+4\beta_1)})+\ln(1+e^{-(\beta_0+3\beta_1)})]+\ln(1-\frac{1}{1+e^{-(\beta_0+2\beta_1)}})+\ln(1-\frac{1}{1+e^{-(\beta_0+\beta_1)}})$

## Problem 4

```{r Problem 4}
b<-read.csv("/Users/newuser/Desktop/Notes/Graduate/STAT 408 - Applied Regression Analysis/births.csv")
```

### Problem 4a

```{r Problem 4a}
set.seed(2022)                    # Lecture 16, Slide 12
samp<-sample(nrow(b),round(0.8*nrow(b)))
train<-b[samp,]
test<-b[-samp,]
ptest<-predict(lm(weight~.,data=train),test)
mean((test$weight-ptest)^2)       # Lecture 16, Slide 13
sqrt(mean((test$weight-ptest)^2)) # Lecture 16, Slides 14-15
sqrt(mean((test$weight-ptest)^2))/mean(test$weight)
```

We can see the mean squared error (MSE) of the predictions on the test set is `r mean((test$weight-ptest)^2)`, the root mean squared error (RMSE) of the predictions on the test set is `r sqrt(mean((test$weight-ptest)^2))`, and the normalized root mean squared error (NRMSE) of the predictions on the test set is `r sqrt(mean((test$weight-ptest)^2))/mean(test$weight)`. We estimate there is approximately a `r 100*sqrt(mean((test$weight-ptest)^2))/mean(test$weight)` percent error in predicting the birth weight of a baby for this linear model.

### Problem 4b

```{r Problem 4b}
ptrain<-predict(lm(weight~.,data=train),train)
mean((train$weight-ptrain)^2)
sqrt(mean((train$weight-ptrain)^2))
sqrt(mean((train$weight-ptrain)^2))/mean(train$weight)
```

We can see the MSE of the predictions on the training set is `r mean((train$weight-ptrain)^2)`, the RMSE of the predictions on the training set is `r sqrt(mean((train$weight-ptrain)^2))`, and the NRMSE of the predictions on the training set is `r sqrt(mean((train$weight-ptrain)^2))/mean(train$weight)`. Looking at the results from problem 4a, we find that these three values are all less than the corresponding values for the test set. Because the linear model was trained using the training set, it makes sense that these three values would be lower when using the model to make predictions on the same dataset.

### Problem 4c

```{r Problem 4c, warning=FALSE}
MSE<-c()                          # Lecture 16, Slide 18
set.seed(2022)
for(k in split(sample(1:nrow(b)),cut(1:nrow(b),5,labels=FALSE))){cvtrain<-b[k,]
  cvtest<-b[-k,]
  MSE<-c(MSE,mean((cvtest$weight-predict(lm(weight~.,data=cvtrain),cvtest))^2))}
plot(1:5,MSE,type="b",xlab="Fold Number",ylab="Mean Squared Error (MSE)",main="Mean Squared Error (MSE) by Fold for 5-Fold Cross Validation")
abline(h=mean(MSE),lty=2)
mean(MSE)
```

We can see the average mean squared error obtained from 5-fold cross-validation on the test set is `r mean(MSE)`.