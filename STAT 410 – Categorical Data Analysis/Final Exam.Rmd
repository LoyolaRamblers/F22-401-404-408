---
title: "STAT 410 Final Exam"
author: "Charles Hwang"
date: "7 May 2022"
output: html_document
editor_options: 
  chunk_output_type: console
---
This is a take-home exam. Submit this R Markdown pdf file and html file it compiles that includes your solutions -code, output, explanation/conclusions etc. Provide as much details and explanation as possible. If you ran multiple models/testing things out please show that and describe your process/choices. Make sure that your work is done by *you only and is completely original*. Anyone caught cheating will receive an automatic zero in the exam. Do not cheat.. Seriously please don't do it.

## Problem Breakdown
* 310 Students must complete the first 5 questions (1-5) (each question is worth 20pts out of 100pts)
* 410 Students must complete all the questions (each question is worth 20pts out of 120 pts)

## Data Description
This data set comes from the City of Chicago Data Portal and is about food safety inspections throughout the city from 2010 to present. In the original file there are many variable and more information about them can be found [here](http://bit.ly/tS9IE8). I cleaned the dataset to its current form, found in data folder (inspections_clean.csv). Please note information about the following variables.

* `license_number` - a unique license number that corresponds to the business/establishment. This is different than `inspection_id` which is unique for each inspection.
* `facility_type` - this is what type of facility the business/establishment is. I cleaned to data to be only 9 categories with the most common being restaurant. For more information of the cleaning please see data_cleaning.R
* `risk` - a categorization made from Dept. of Public Health to assess the risk of adversely
affecting the publicâ€™s health, with 1 being the highest and 3 the lowest. Please see data description for more information.
* `inspection_type` - there are 3 categories that I cleaned the data to include; canvas, complaint, and license. Please see data description for more information.
* `results` - I cleaned this response to include three options: pass, conditional pass, and fail. The original had others but I selected these three as the only options.
* `violations` - a string vector of violations that were present at the inspection. Could be beyond the scope of the final but I thought you might find this interesting.

Please take some time to examine the dataset. There should be 127,903 observations with 11 variables in the original data. For you own final analysis, I would like you to work with a subsample of the data that will be specific to you. This will create a unique sample (n = 50,000) for each student and highlight your interpretations of your analysis. Please set a unique seed, like your birthday or last 4 of your phone number, etc. You will use this for the rest of the exam.
```{r data-explore, message=FALSE, warning=FALSE, results='hold'}
library(tidyverse)
inspection<-read_csv("/Users/newuser/Desktop/Notes/Graduate/STAT 410 - Categorical Data Analysis/final/data/inspections_clean.csv")
### data explore here
par(mfrow=c(2,1))
boxplot(inspection$inspection_id,main="Histogram of Inspection ID",horizontal=TRUE)
boxplot(inspection$license_number,main="Histogram of License Number",horizontal=TRUE)
hist(inspection$inspection_date,breaks="years",xaxt="n",xlab="Year",freq=TRUE,main="Histogram of Dates of Food Inspections")
axis.Date(1,at=seq(min(inspection$inspection_date),max(inspection$inspection_date),by="1 year"),format="'%y")
plot(inspection$inspection_date,inspection$inspection_id,xaxt="n",xlab="Inspection Date",ylab="Inspection ID",main="Inspection ID vs. Inspection Date") # Logarithmic fit
axis.Date(1,at=seq(min(inspection$inspection_date),max(inspection$inspection_date),by="1 year"),format="'%y")
summary(inspection$inspection_id)
length(unique(inspection$dba_name))
head(sort(table(inspection$license_number),decreasing=TRUE))
table(inspection$facility_type)
table(inspection$risk)
head(sort(table(inspection$address),decreasing=TRUE),36) # Midway Airport, Union Station, shopping centers, etc.
table(inspection$zip)
table(inspection$inspection_type)
table(inspection$results)
length(unique(inspection$violations)) # Over 86 percent of recorded entries in violations column are unique
table(inspection$risk,inspection$results) # No apparent difference in probability of passing between risk levels
table(inspection$inspection_type,inspection$results)
### my random subsample
set.seed(7522,sample.kind="Rounding")
inspect_sub<-inspection[sample(nrow(inspection),50000),]
```

1. Please perform a Chi-squared test of independence between `result` and `inspection_type`. You will need to recategorize `result` to pass and fail (conditional pass is a pass). Interpret your results (include a residual plot). What is this test asking? Why would you be performing this test?

```{r q1, results='hold'}
inspect_sub[inspect_sub$results=="Pass w/ Conditions","results"]<-"Pass"
Result<-inspect_sub$results
Type<-inspect_sub$inspection_type
table(Result,Type)
chisq.test(table(Result,Type))
library(vcd)
mosaic(xtabs(~Result+Type))
```

## Answer 1:

$H_0:$ There is *no* association between type of inspection and result

$H_A:$ There is *an* association between type of inspection and result

We reject $H_0$ at the $\alpha=0.05$ level. There is strong statistical evidence ($\chi_2=$ `r chisq.test(table(Result,Type))$statistic`, $p=$ `r chisq.test(table(Result,Type))$p.value`) that there is an association between type of inspection and result. The purpose of performing this test is to determine whether type of inspection and result may be related to one another to guide additional analysis.

2. Using the binary variable created in question 1 for result of the inspection (pass/fail), create a model using the variables `facility_type`, `risk`, `zip`, and `inspection_type`. Please describe your process of model selection (Chapter 5 tools) and interpret your final model result (at least one $\beta$). Some kind of LRT should be performed.
* Comment on whether or not you factorized certain variables and why.

```{r model1, results='hold'}
inspect_sub$results<-factor(inspect_sub$results,labels=0:1)
inspect_sub$facility_type<-as.factor(inspect_sub$facility_type)
inspect_sub$risk<-as.factor(inspect_sub$risk)
inspect_sub$zip<-as.factor(inspect_sub$zip)
inspect_sub$inspection_type<-as.factor(inspect_sub$inspection_type)
f<-glm(results~facility_type,family=binomial,data=inspect_sub)                          # Step 1
r<-glm(results~risk,family=binomial,data=inspect_sub)
z<-glm(results~zip,family=binomial,data=inspect_sub)
i<-glm(results~inspection_type,family=binomial,data=inspect_sub)
1-pchisq(f$null.deviance-f$deviance,f$df.null-f$df.residual)                    # ***
1-pchisq(r$null.deviance-r$deviance,r$df.null-r$df.residual)                    # ***
1-pchisq(z$null.deviance-z$deviance,z$df.null-z$df.residual)                    # ***
1-pchisq(i$null.deviance-i$deviance,i$df.null-i$df.residual)                    # ***
fri<-glm(results~facility_type+risk+inspection_type,family=binomial,data=inspect_sub)   # Step 2
1-pchisq(fri$null.deviance-fri$deviance,fri$df.null-fri$df.residual)            # ***
fxri<-glm(results~facility_type*risk+inspection_type,family=binomial,data=inspect_sub)  # Step 3
fxir<-glm(results~facility_type*inspection_type+risk,family=binomial,data=inspect_sub)
frxi<-glm(results~facility_type+risk*inspection_type,family=binomial,data=inspect_sub)
1-pchisq(fri$deviance-fxri$deviance,fri$df.residual-fxri$df.residual)           # ***
1-pchisq(fri$deviance-fxir$deviance,fri$df.residual-fxir$df.residual)           # ***
1-pchisq(fri$deviance-frxi$deviance,fri$df.residual-frxi$df.residual)           # ***
fxrfxirxi<-glm(results~facility_type*risk+facility_type*inspection_type+risk*inspection_type,family=binomial,data=inspect_sub)                                                                           # Step 4
1-pchisq(fri$deviance-fxrfxirxi$deviance,fri$df.residual-fxrfxirxi$df.residual) # ***
fxrxi<-glm(results~facility_type*risk*inspection_type,family=binomial,data=inspect_sub) # Step 5
1-pchisq(fri$deviance-fxrxi$deviance,fri$df.residual-fxrxi$df.residual)         # " "
summary(step(fxrfxirxi,direction="both",trace=0))                                       # Step 6
```

## Answer 2:

I set all four variables as factors. ZIP code was set as a factor because the ZIP codes of Chicago do not have any geographic order. The other three variables were set as factors due to being qualitative. The model selection began by comparing the null model to the four single-variable models (Step 1) and the LRT found they were all strongly significant ($p=$ `r 1-pchisq(f$null.deviance-f$deviance,f$df.null-f$df.residual)`, $p=$ `r 1-pchisq(r$null.deviance-r$deviance,r$df.null-r$df.residual)`, $p=$ `r 1-pchisq(z$null.deviance-z$deviance,z$df.null-z$df.residual)`, $p=$ `r 1-pchisq(i$null.deviance-i$deviance,i$df.null-i$df.residual)`). However, I chose to exclude the ZIP code variable because it had `r length(table(inspect_sub$zip))` levels which would be impractical to interpret, especially with interaction terms, and additionally none of the individual levels were significant at the $\alpha=0.2$ level (the most significant was 60604 with $p=$ `r min(summary(z)$coefficients[,"Pr(>|z|)"])`).

I fit a model with all three remaining variables (Step 2) and the LRT again found the deviance was significantly less than that in the null model ($\chi_{12}=$ `r fri$null.deviance-fri$deviance`, $p=$ `r 1-pchisq(fri$null.deviance-fri$deviance,fri$df.null-fri$df.residual)`). I fit models that included the three possible two-variable interaction terms (Step 3) and the LRT found them all to be significantly better than the three-variable model without interaction ($p=$ `r 1-pchisq(fri$deviance-fxri$deviance,fri$df.residual-fxri$df.residual)`, $p=$ `r 1-pchisq(fri$deviance-fxir$deviance,fri$df.residual-fxir$df.residual)`, $p=$ `r 1-pchisq(fri$deviance-frxi$deviance,fri$df.residual-frxi$df.residual)`). A model that included all three of these interaction pairs (Step 4) was also significant ($\chi_{31}=$ `r fri$deviance-fxrfxirxi$deviance`, $p=$ `r 1-pchisq(fri$deviance-fxrfxirxi$deviance,fri$df.residual-fxrfxirxi$df.residual)`). However, when I fit the same model including a three-way interaction (Step 5), it was not significant ($\chi_{50}=$ `r format(fri$deviance-fxrxi$deviance,scientific=FALSE)`, $p=$ `r 1-pchisq(fri$deviance-fxrxi$deviance,fri$df.residual-fxrxi$df.residual)`) and actually increased the deviance by more than twofold. I verified my results by using the `step()` function (Step 6) on the model from **Step 4** and it concurred that that model appeared to be the "best" model with a Akaike information criterion (AIC) value of `r format(fxrfxirxi$aic,scientific=FALSE)`.

The interpretation of the model is difficult as there are $f+r+t+fr+ft+rt-5=43$ coefficients (where $f=9-1=8$ variables for facility type, $r=3-1=2$ variables for risk, and $t=3-1=2$ variables for inspection type, and 5 interaction terms were excluded for having only one value), but we can see most coefficients are not significant in the model. However, at least one coefficient from every variable and interaction is significant at the $\alpha=0.1$ level. The most significant is the interaction term between medium risk and license inspection ($p=$ `r format(summary(fxrfxirxi)$coefficients["riskRisk 2 (Medium):inspection_typelicense","Pr(>|z|)"],scientific=FALSE)`), followed by restaurant ($p=$ `r summary(fxrfxirxi)$coefficients["facility_typerestaurant","Pr(>|z|)"]`) and school facility ($p=$ `r summary(fxrfxirxi)$coefficients["facility_typeschool","Pr(>|z|)"]`). Hospital facility, low risk/complaint inspection, liquor store/complaint inspection, and gas station were also significant at the $\alpha=0.05$ level, and grocery store, restaurant/medium risk, and license inspection were significant at the $\alpha=0.1$ level.

Among the single levels significant at the $\alpha=0.05$ level, hospital facility had the greatest effect (`r summary(fxrfxirxi)$coefficients["facility_typehospital","Estimate"]`). The **estimated odds** of a hospital facility passing an inspection are approximately `r exp(summary(fxrfxirxi)$coefficients["facility_typehospital","Estimate"])` times greater than the estimated odds of a bakery facility (null facility variable) passing an inspection. There were several variables that had large effect sizes, including liquor store, liquor store/medium risk, and grocery/low risk, but with no statistical significance ($p>0.9$).

 3. Either perform a baseline-category logit model or a cumulative logit model for the outcome of `result` in its original form (using previous explanatory variable from question 2 except using `zip`). Describe why you picked the model you picked, write out what the model would look like ($\alpha's$ and $\beta's$), and interpret the results of your model (at lease one $\beta$ parameter and the overall fit of the model through a hypothesis test).
 
```{r model2, results='hold'}
set.seed(7522,sample.kind="Rounding")
inspect_sub<-inspection[sample(nrow(inspection),50000),]
library(VGAM)
L<-vglm(results~facility_type+risk+inspection_type,family=multinomial(refLevel="Fail"),data=inspect_sub)
summary(L)
Lc<-vglm(results~facility_type+risk+inspection_type,family=multinomial(refLevel="Pass w/ Conditions"),data=inspect_sub)
summary(Lc)
1-pchisq(L@criterion$deviance,L@df.residual)
1-pchisq(Lc@criterion$deviance,Lc@df.residual)
```
 
## Answer 3:

I ran a baseline-category logit model on the data because it seemed more appropriate with the outcome variable. The "Pass w/ Conditions" level has different specific conditions for each inspection, and it seems intuitive, but it's not entirely clear it should be classified between the "Pass" and "Fail" levels without knowing more about these conditions. Additional analysis on the conditions may warrant that a cumulative logit model is more appropriate. The equations I obtained from the baseline-category logit model were approximately:

$\log(\frac{\hat{\pi}_P}{\hat{\pi}_F})=0.788+0.325x_{Fc}-0.251x_{Fgas}+0.090x_{Fg}+0.711x_{Fh}-0.378x_{Fl}+0.096x_{Flt}+0.361x_{Fr}+0.583x_{Fs}+0.027x_{R2}-0.045x_{R3}-0.435x_{Tc}-0.485x_{Tl}$

$\log(\frac{\hat{\pi}_{Pw}}{\hat{\pi}_F})=-0.351+0.124x_{Fc}-0.011x_{Fgas}+0.244x_{Fg}+0.603x_{Fh}-0.066x_{Fl}+0.034x_{Flt}+0.499x_{Fr}-0.032x_{Fs}-0.001x_{R2}-0.376x_{R3}-0.322x_{Tc}-1.263x_{Tl}$

$\log(\frac{\hat{\pi}_P}{\hat{\pi}_{Pw}})=\log(\frac{\hat{\pi}_P}{\hat{\pi}_F})-\log(\frac{\hat{\pi}_{Pw}}{\hat{\pi}_F})=1.14+0.20x_{Fc}-0.24x_{Fgas}-0.15x_{Fg}+0.11x_{Fh}-0.31x_{Fl}+0.06x_{Flt}-0.14x_{Fr}+0.62x_{Fs}+0.03x_{R2}+0.33x_{R3}-0.11x_{Tc}+0.78x_{Tl}$,

where

$\hat{\pi}_P:$ estimated probability of passing inspection,

$\hat{\pi}_{Pw}:$ estimated probability of passing inspection with conditions,

$\hat{\pi}_F:$ estimated probability of failing inspection,

$\alpha:$ intercept term,

$\beta_{Fc}:$ coefficient for catering facility,

$x_{Fc}:$ dummy variable for catering facility,

$\beta_{Fgas}:$ coefficient for gas station facility,

$x_{Fgas}:$ dummy variable for gas station facility,

$\beta_{Fg}:$ coefficient for grocery store facility,

$x_{Fg}:$ dummy variable for grocery store facility,

$\beta_{Fh}:$ coefficient for hospital facility,

$x_{Fh}:$ dummy variable for hospital facility,

$\beta_{Fl}:$ coefficient for liquor store facility,

$x_{Fl}:$ dummy variable for liquor store facility,

$\beta_{Flt}:$ coefficient for long-term care facility,

$x_{Flt}:$ dummy variable for long-term care facility,

$\beta_{Fr}:$ coefficient for restaurant facility,

$x_{Fr}:$ dummy variable for restaurant facility,

$\beta_{Fs}:$ coefficient for school facility,

$x_{Fs}:$ dummy variable for school facility,

$\beta_{R2}:$ coefficient for medium risk,

$x_{R2}:$ dummy variable for medium risk,

$\beta_{R3}:$ coefficient for low risk,

$x_{R3}:$ dummy variable for low risk,

$\beta_{Tc}:$ coefficient for complaint inspection,

$x_{Tc}:$ dummy variable for complaint inspection,

$\beta_{Tl}:$ coefficient for license inspection, and

$x_{Tl}:$ dummy variable for license inspection.

We can see for the $\log(\frac{\hat{\pi}_P}{\hat{\pi}_F})$ model that inspection type (both license and complaint) are strongly significant ($p=$ `r summary(L)@coef3["inspection_typelicense:1","Pr(>|z|)"]`, $p=$ `r summary(L)@coef3["inspection_typecomplaint:1","Pr(>|z|)"]`), as well as the school, restaurant, hospital, catering, and liquor store facilities at the $\alpha=0.05$ level. Among these, hospital facility had the greatest effect (`r summary(L)@coef3["facility_typehospital:1","Estimate"]`), with school facility and both inspection type variables also having large effects. The **estimated odds** of a hospital facility passing an inspection are approximately `r exp(summary(L)@coef3["facility_typehospital:1","Estimate"])` times greater than the estimated odds of a bakery facility (null facility variable) passing an inspection.

For the $\log(\frac{\hat{\pi}_{Pw}}{\hat{\pi}_F})$ model, both inspection type variables were again strongly significant ($p=$ `r summary(L)@coef3["inspection_typelicense:2","Pr(>|z|)"]`, $p=$ `r summary(L)@coef3["inspection_typecomplaint:2","Pr(>|z|)"]`). Low risk and grocery store facility were significant at the $\alpha=0.05$ level in addition to the same restaurant and hospital facilities that were significant in the previous model. Among these, license inspection had the greatest effect by far (`r summary(L)@coef3["inspection_typelicense:2","Estimate"]`), followed by hospital and restaurant facilities. The **estimated odds** of a license inspection passing are approximately `r exp(summary(L)@coef3["inspection_typelicense:2","Estimate"])` times greater than the estimated odds of a canvass inspection (null inspection type variable) passing.

Lastly, for the $\log(\frac{\hat{\pi}_P}{\hat{\pi}_{Pw}})$ model, both inspection type variables were still significant ($p=$ `r summary(Lc)@coef3["inspection_typelicense:2","Pr(>|z|)"]`, $p=$ `r format(summary(Lc)@coef3["inspection_typecomplaint:2","Pr(>|z|)"],scientific=FALSE)`), but complaint inspection was not as significant as school facility and low risk. License inspection had the greatest effect (`r summary(Lc)@coef3["inspection_typelicense:2","Estimate"]`), followed by school facility, low risk, and complaint inspection. The **estimated odds** of a license inspection passing are approximately `r exp(summary(Lc)@coef3["inspection_typelicense:2","Estimate"])` times greater than the estimated odds of a canvass inspection (null inspection type variable) passing. When performing multinomial model goodness-of-fit tests, we find the null hypotheses for the models soundly fail to be rejected ($\chi_{99974}=$ `r format(L@criterion$deviance,scientific=FALSE)`, $p=$ `r 1-pchisq(L@criterion$deviance,L@df.residual)`), indicating the **model fits well**.

 4. Perform a marginal model for a clustered binary response (`result` with only success or failure). You must clearly state 
 * What is the "cluster" here? What variable will you use from the data to express the clustering structure in the model? (Write out the model).
 * What is the correlation structure you assumed? Why did you assume that?
 * Interpret at least one $\beta$ and compare the naive and robust standard errors from the model. 
 * Can you make likelihood based inferences on this model like you did in question 2 or 3?
 
```{r model3, results='hold'}
inspect_4<-inspection[10100:10800,] # New subset per Campuswire discussion (https://campuswire.com/c/G1B989FE6/feed/75)
inspect_4[inspect_4$results=="Pass w/ Conditions","results"]<-"Pass"
inspect_4$results<-factor(inspect_4$results,labels=0:1)
library(gee)
gee<-gee(results~facility_type+risk+inspection_type,id=license_number,corstr="exchangeable",family=binomial,data=inspect_4)
summary(gee)
```
 
## Answer 4:

I believe the most appropriate variable for a cluster is **license number**. The inspection ID would not be the most appropriate as it is unique for each inspection, and by clustering on license number we can look at all inspections for a single license (or facility). Other candidates like name DBA and address would also not be completely accurate as there could be multiple facilities with the same name or at the same address. The corresponding generalized estimating equation (GEE) is:

$logit[P(Y_t=1)]=1.094+0.398z_{Fc}-0.325z_{Fg}+0.184z_{Flt}+0.233z_{Fr}+1.296z_{Fs}+0.018z_{R2}-0.446z_{R3}+0.008z_{Tc}-0.545z_{Tl}+\gamma x$

where

$\alpha=1.094:$ intercept term,

$\beta_{Fc}=0.398:$ coefficient for catering facility,

$z_{Fc}:$ dummy variable for catering facility,

$\beta_{Fg}=-0.325:$ coefficient for grocery store facility,

$z_{Fg}:$ dummy variable for grocery store facility,

$\beta_{Flt}=0.184:$ coefficient for long-term care facility,

$z_{Flt}:$ dummy variable for long-term care facility,

$\beta_{Fr}=0.233:$ coefficient for restaurant facility,

$z_{Fr}:$ dummy variable for restaurant facility,

$\beta_{Fs}=1.296:$ coefficient for school facility,

$z_{Fs}:$ dummy variable for school facility,

$\beta_{R2}=0.018:$ coefficient for medium risk,

$z_{R2}:$ dummy variable for medium risk,

$\beta_{R3}=-0.446:$ coefficient for low risk,

$z_{R3}:$ dummy variable for low risk,

$\beta_{Tc}=0.008:$ coefficient for complaint inspection,

$z_{Tc}:$ dummy variable for complaint inspection,

$\beta_{Tl}=-0.545:$ coefficient for license inspection, and

$z_{Tl}:$ dummy variable for license inspection.

I decided to use the **exchangeable** correlation structure as the facility type, risk, and inspection type do not appear to be completely independent, as seen from the statistical significance of the interaction terms in the generalized linear models (GLM), but the correlations between variables were also not entirely different from one another. The textbook writes in Section 9.2.2 (page 257): "In practice, usually little if any *a priori* information is available about the correlation structure. ... Unless you expect dramatic differences among the correlations, we recommend using the exchangeable working correlation structure." We can see from the output that school type has by far the greatest effect (`r gee$coefficients["facility_typeschool"]`), followed by license inspection and restaurant type. The **estimated odds** of a school facility passing an inspection are approximately `r exp(gee$coefficients["facility_typeschool"])` times the estimated odds of a bakery facility (null facility variable) passing an inspection. We can see there are **significant differences** between the naive and robust standard errors for all variables, leading to different $z$-statistics. This may be because of the large number of variables in the model. The robust standard errors were all smaller than the naive standard errors which actually would have led to different conclusions at the $\alpha=0.05$ level for the school type variable.

The equation does not have a known distribution, causing a loss of generality, so likelihood-based inferences **cannot** be made on this model. The textbook explains these limitations in Section 9.2.4 (page 259) and Section 10.2.5 (page 283), writing: "Because the GEE method does not specify the complete multivariate distribution, it does not have a likelihood function. In this sense, the GEE method is a multivariate type of quasi-likelihood method. Therefore, its estimates are not ML estimates. ... With the GEE approach to fitting marginal models, a drawback is that likelihood-based inferences are not available. The GEE approach does not specify a joint distribution of the responses, so it does not have a likelihood function."

 5. Perform a GLMM on the response `result` as a binary response. You must clearly state
 * What would be the logical choice of a random effect here? How will we signify that in the model? (Write out the model).
 * Interpret at least one $\beta$ and the standard deviation of the random effect. How is the model fitting?
 * Discuss a comparison of the marginal vs GLMM model. Not only in terms of parameters but also discuss how this changes the interpretation and assumptions being made about each model. Why would you use one over the other? Which one do you think is correct for this dataset?
 
```{r mod4, results='hold'}
inspect_sub[inspect_sub$results=="Pass w/ Conditions","results"]<-"Pass"
inspect_sub$results<-factor(inspect_sub$results,labels=0:1)
library(lme4)
glmm<-glmer(results~(1|license_number)+facility_type+risk+inspection_type,family=binomial,nAGQ=20,data=inspect_sub)
summary(glmm)
as.numeric(1-pchisq(summary(glmm)$AICtab["deviance"],summary(glmm)$AICtab["df.resid"]))
library(geepack)
inspect_sub$results<-as.numeric(inspect_sub$results)-1
gw<-geeglm(results~facility_type+risk+inspection_type,id=license_number,corstr="exchangeable",family="binomial",data=inspect_sub)
anova(gw)
```
  
## Answer 5:

The logical choice of a random effect would again be the **license number** for the same reasons as in the GEE. This would be signified in the model as $\{u_i\}$, with the full model being:

$logit[P(Y_{it}=1)]=u_i+1.07698973+\hat{\beta}_f+\hat{\beta}_r+\hat{\beta}_t+\gamma x$

where

$\{u_i\}:$ intercept term for license number $i$,

$\hat{\alpha}=1.07698973:$ estimated general intercept term,

$\hat{\beta}_{f}:$ estimated coefficient for facility;

|        where
|        $f=b$ for bakery ($\hat{\beta}_b=0$),
|        $f=c$ for catering ($\hat{\beta}_c=0.29870541$),
|        $f=gas$ for gas station ($\hat{\beta}_{gas}=-0.20549148$),
|        $f=g$ for grocery store ($\hat{\beta}_g=0.11958310$),
|        $f=h$ for hospital ($\hat{\beta}_h=0.68540966$),
|        $f=q$ for liquor store ($\hat{\beta}_q=-0.32696931$),
|        $f=lt$ for long-term care ($\hat{\beta}_{lt}=0.08006439$),
|        $f=r$ for restaurant ($\hat{\beta}_r=0.39217254$), and
|        $f=s$ for school ($\hat{\beta}_s=0.48331578$);

$\hat{\beta}_{r}:$ estimated coefficient for risk;

|        where 
|        $r=1$ for low risk ($\hat{\beta}_1=0$)
|        $r=2$ for medium risk ($\hat{\beta}_2=0.01849662$), and
|        $r=3$ for high risk ($\hat{\beta}_3=-0.10966511$); and

$\hat{\beta}_{t}:$ estimated coefficient for type of inspection;

|        where
|        $t=cv$ for canvass ($\hat{\beta}_{cv}=0$)
|        $t=ci$ for complaint inspection ($\hat{\beta}_{ci}=-0.40053479$), and
|        $t=l$ for license ($\hat{\beta}_l=-0.62597678$).



Inspection type is again strongly significant ($p=$ `r summary(glmm)$coefficients["inspection_typelicense","Pr(>|z|)"]`, $p=$ `r summary(glmm)$coefficients["inspection_typecomplaint","Pr(>|z|)"]`), followed by school and restaurant facilities. Hospital and catering facilities are also significant along with low risk. Among these, hospital facility has the greatest effect (`r summary(glmm)$coefficients["facility_typehospital","Estimate"]`), followed by license inspection and school facility. The **estimated odds** of a hospital facility passing an inspection are approximately `r exp(summary(glmm)$coefficients["facility_typehospital","Estimate"])` times the estimated odds of a bakery facility (null facility variable) passing an inspection. We can also see that the **standard deviation of the random effect** $\hat{\sigma}=$ `r glmm@theta`. A one-standard deviation change in the individual intercept term between license numbers is approximately a 17.6 percent change in probability of passing an inspection, holding all other variables constant.

We reject $H_0$ at the $\alpha=0.05$ level for the $\chi^2$ test. There is strong statistical evidence ($\chi_{49986}=$ `r format(summary(glmm)$AICtab["deviance"],scientific=FALSE)`, $p=$ `r 1-pchisq(summary(glmm)$AICtab["deviance"],summary(glmm)$AICtab["df.resid"])`) that the **model fits well**. Additionally, we reject $H_0$ at the $\alpha=0.05$ level for all three variables (facility type, risk level, and inspection type). There is sufficient evidence ($p=$ `r anova(gw)["facility_type","P(>|Chi|)"]`, $p=$ `r format(anova(gw)["risk","P(>|Chi|)"],scientific=FALSE)`, $p=$ `r anova(gw)["inspection_type","P(>|Chi|)"]`) that at least one $\beta_f$, $\beta_r$, and $\beta_t$ is different.

The results from the GEE and the generalized linear mixed model (GLMM) are *relatively* similar. It is difficult to compare them directly since they were performed on different and different-sized subsets, but the methods of interpreting variables remain the same. The **main assumption** for the GEE is on the correlation structure of the variables (independence, exchangeable, unstructured, etc.), while the GLMM requires an approximate normality assumption on all variables. For these data, using a GEE would be to compare results between different license numbers with the marginal probabilities, while using a GLMM would be more to compare results within each license number. Both models are available and the more appropriate model would **depend on the specific analysis** being conducted. For predicting the result of an inspection, I believe the GLMM would be more appropriate as prior results for a given license number would be relevant. Alternatively, if comparing the results of multiple facilities with one another (e.g., the proportion of passed inspections for each facility), I believe the GEE would be more appropriate.

 6. Graduate Student questions: You do not have to model in R and this can be written out and attached to the upload.
 a) Describe what a transitional model would look like for this data. What is the point of adding a transitional term to the model and what assumption are be making when we use it?  What would the $\beta$ parameter be describing/interpreted as? What would the difference between first order and second order term be? What is the max order term we could use in this data (how far back in time can we go?)?
 b) If you could make this dataset be a multilevel model what would your first and second level models be? Hypothesize other variables you might have about the business/establishment (full dataset have year of creation, etc.). Would you have random effects and if so at which level?
 
## Answer 6:

(**a**) A transitional model would incorporate the inspection date variable in an attempt to predict the outcome of future inspections. The main assumption being made would be that all past inspections recorded except the last (most recent) one are **conditionally independent**, which may not necessarily be true (follow-up or duplicate inspections, violation-specific inspections, etc.). In the model, $\beta$ would represent the coefficient for the result of the previous inspection, with a greater effect ($|\beta|$) indicating a greater influence of the previous inspection result on the model. The first-order Markov model would only account for the **result of the last inspection**, while the second-order Markov model would account for the results of the previous two inspections. Accordingly, the $n$th-order model would account for the results of the previous $n$ inspections. The maximum order term we would be able to use would be the number of inspections in the data (50,000) and we would be able to go back to the earliest inspection listed (`r format(min(inspect_sub$inspection_date),format="%B %d, %Y")`). However, this would be less useful as the previous methods used in this exam, as it would be impractical to interpret that many terms in the model and it seems that accounting for every previous inspection would defeat the purpose of using a Markov model to begin with.

(**b**) Looking at the variables in the data, it seems like license number and facility type would be logical choices for the first and second levels respectively. Variability between licenses would be captured by the first level and variability between facility types would be captured by the second level. Alternate choices for first and second levels could be inspection ID and license number to capture variability between inspections and types of licenses, or maybe address and ZIP code to capture variability between locations and ZIP codes. There are countless **other variables** that could be added to a multilevel model, but I think square area, number of entrances/exits, and floor number(s) of the facility, expired business (or other applicable) permit (binary), Americans with Disabilities Act compliance (binary), alcohol sale (binary), public restrooms (binary), and customer rating (Yelp, Facebook, etc.) could be suitable variables. These variables could all be random effects on the **first level**.